{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Ciencia de Datos: Tarea 2\n",
    "\n",
    "Este notebook contiene el código de base para realizar la Tarea 2 del curso. Puede copiarlo en su propio repositorio y trabajar sobre el mismo.\n",
    "Las **instrucciones para ejecutar el notebook** están en la [página inicial del repositorio](https://gitlab.fing.edu.uy/maestria-cdaa/intro-cd/).\n",
    "\n",
    "**Se espera que no sea necesario revisar el código para corregir la tarea**, ya que todos los resultados y análisis relevantes deberían estar en el **informe en formato PDF**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar bibliotecas (dependencias)\n",
    "Recuerde instalar los requerimientos (`requirements.txt`) en el mismo entorno donde está ejecutando este notebook (ver [README](https://gitlab.fing.edu.uy/maestria-cdaa/intro-cd/)). Para la entrega 2 hay nuevas dependencias, por lo que es importante correr la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame con todos los discursos:\n",
    "df_speeches = pd.read_csv('./data/us_2020_election_speeches.csv')\n",
    "df_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la limpieza de los datos que crea pertinente. Se espera que usen la función clean_text() de la entrega anterior.\n",
    "# df_speeches_clean = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb61c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los 3 candidatos con más discursos.\n",
    "\n",
    "# top_5_candidates = df_speeches_clean[\"speaker\"].value_counts().head(5).index\n",
    "# print(f\"Top 3 candidatos: {top_3_candidates}\")\n",
    "# print(\"---------------\")\n",
    "\n",
    "# df_speeches_top_3 = df_speeches_clean[\n",
    "#     df_speeches_clean[\"speaker\"].isin(top_3_candidates)\n",
    "# ]\n",
    "# df_speeches_top_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7f004",
   "metadata": {},
   "source": [
    "## Parte 1: Dataset y representación numérica de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Separar 30% del conjunto para test. Al resto lo llamamos \"dev\" (desarrollo).\n",
    "\n",
    "# X_dev, X_test, y_dev, y_test = ...\n",
    "# print(f\"Tamaños de los conjuntos: {X_dev.shape}, {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Visualización de la proporción de cada candidato por conjunto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab89198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Transforme el texto del conjunto de entrenamiento a la representación numérica (features) de conteo de palabras o bag of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Obtenga la representación numérica Term Frequency - Inverse Document Frequency.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31172c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 :Muestre en un mapa el conjunto de entrenamiento, utilizando las dos primeras componentes PCA sobre los vectores de tf-idf.\n",
    "\n",
    "\n",
    "# Haga una visualización que permita entender cómo varía la varianza explicada a medida que se agregan componentes (e.g: hasta 10 componentes).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272f140",
   "metadata": {},
   "source": [
    "## Parte 2: Entrenamiento y Evaluación de Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Entrene el modelo Multinomial Naive Bayes, luego utilícelo para predecir sobre el conjunto de test, y reporte el valor de accuracy y la matriz de confusión. Reporte el valor de precision y recall para cada candidato. \n",
    "# Calcular matriz de confusión Sugerencia: utilice el método from_predictions de ConfusionMatrixDisplay para realizar la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3abeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Implemente una búsqueda de hiperparámetros usando GridSearchCV.\n",
    "\n",
    "# Genere una visualización que permita comparar las métricas (e.g: accuracy) de los distintos modelos entrenados, viendo el valor promedio y variabilidad de las mismas en todos los splits (e.g: en un gráfico de violín).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Elija el mejor modelo (mejores parámetros) y vuelva a entrenar sobre todo el conjunto de entrenamiento disponible (sin quitar datos para validación). Reporte el valor final de las métricas y la matriz de confusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233006b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Evalúe con validación cruzada al menos un modelo más (dentro de scikit-learn) aparte de Multinomial Naive Bayes para clasificar el texto utilizando las mismas features de texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25201dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Evalúe el problema cambiando al menos un candidato. En particular, observe el (des)balance de datos y los problemas que pueda generar, así como cualquier indicio que pueda ver en el mapeo previo con PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addddaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Repetir la clasificación con los tres candidatos con más discursos, pero esta vez clasificando a nivel de párrafos y no de discursos enteros.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".introcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
